{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic  \\\n",
       "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...           1.0   \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...           1.0   \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...           0.0   \n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜           0.0   \n",
       "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...           1.0   \n",
       "\n",
       "   Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
       "0         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN        NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'urdu_sarcastic_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ø¢Ø¦ÛŒ', 'Ø¢Ø¦Û’', 'Ø¢Ø¬', 'Ø¢Ø®Ø±', 'Ø¢Ø®Ø±Ú©Ø¨Ø±', 'Ø¢Ø¯Ù‡ÛŒ', 'Ø¢Ù‹Ø¨', 'Ø¢Ù¹Ú¾', 'Ø¢ÛŒØ¨', 'Ø§Ø©']\n"
     ]
    }
   ],
   "source": [
    "# Load the stopwords from the text file\n",
    "with open('stopwords-ur.txt', 'r', encoding='utf-8') as file:\n",
    "    urdu_stopwords = file.read().splitlines()\n",
    "\n",
    "# Check the first few stopwords\n",
    "print(urdu_stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ Ù„ÛŒÙ†Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’ ğŸ˜ğŸ˜ğŸ˜ğŸ¤£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø§ÛŒØ³ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±ğŸ˜</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
       "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0      ğŸ¤£ğŸ˜‚ğŸ˜‚ Ù„ÛŒÙ†Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’ ğŸ˜ğŸ˜ğŸ˜ğŸ¤£  \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...  \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´...  \n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜  \n",
       "4    `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø§ÛŒØ³ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±ğŸ˜  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove stopwords, handling non-string values\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        words = text.split()  # Split text into words\n",
    "        cleaned_text = ' '.join([word for word in words if word not in urdu_stopwords])\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return text  # Return the text unchanged if it's not a string\n",
    "\n",
    "# Apply the stopword removal to the 'urdu_text' column\n",
    "df['cleaned_text'] = df['urdu_text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the cleaned text\n",
    "df[['urdu_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Punctuation, Emojis, and Hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
       "      <td>ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
       "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
       "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...  \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...  \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...  \n",
       "3                                         Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ†  \n",
       "4  Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # 1. Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # 2. Remove Hashtags\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        \n",
    "        # 3. Remove Punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # 4. Remove all emojis\n",
    "        text = re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FAFF]', '', text)\n",
    "\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return text  # Return unchanged if not a string\n",
    "\n",
    "# Apply the clean_text function to the 'urdu_text' column\n",
    "df['cleaned_text'] = df['urdu_text'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "df[['urdu_text', 'cleaned_text']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Short Conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
       "      <td>ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
       "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
       "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...  \n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...  \n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...  \n",
       "3                                                     \n",
       "4  Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to filter short conversations\n",
    "def filter_short_conversations(text):\n",
    "    if isinstance(text, str):\n",
    "        # Count the number of words\n",
    "        word_count = len(text.split())\n",
    "        # Return the text if it has 3 or more words, otherwise return an empty string\n",
    "        return text if word_count >= 3 else ''\n",
    "    return text  # Return unchanged if not a string\n",
    "\n",
    "# Apply the filter_short_conversations function to the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(filter_short_conversations)\n",
    "\n",
    "# Save the cleaned text to a separate CSV file\n",
    "df[['cleaned_text']].to_csv('cleaned_urdu_text.csv', index=False, encoding='utf-8')\n",
    "# Display the results\n",
    "df[['urdu_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Some additional preprocessing techniques (normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text\n",
       "0  ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...\n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...\n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...\n",
       "3                                                   \n",
       "4  Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given text str, replace one or more spacings with a single space, \n",
    "# and one or more linebreaks with a single newline. \n",
    "\n",
    "from urduhack.preprocessing import normalize_whitespace\n",
    "\n",
    "# Apply normalization to the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: normalize_whitespace(x) if pd.notnull(x) else x)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the normalized text\n",
    "df[['cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...\n",
      "1    Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...\n",
      "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...\n",
      "3                                                     \n",
      "4    Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing some of the additional urdu punctuations from the text\n",
    "\n",
    "from urduhack.preprocessing import remove_punctuation\n",
    "\n",
    "# Ensure all entries in 'cleaned_text' are strings. Replace non-string entries with an empty string.\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Apply remove_punctuation function\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_punctuation)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...\n",
      "1    Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...\n",
      "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...\n",
      "3                                                     \n",
      "4    Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove accents from any accented unicode characters in text str, either by transforming them \n",
    "# into ascii equivalents or removing them entirely.\n",
    "\n",
    "from urduhack.preprocessing import remove_accents\n",
    "\n",
    "# Ensure all entries in 'cleaned_text' are strings. Replace non-string entries with an empty string.\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Apply remove_punctuation function\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_accents)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†...\n",
      "1    Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...\n",
      "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...\n",
      "3                                                     \n",
      "4    Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing english alphabets from the text\n",
    "from urduhack.preprocessing import remove_english_alphabets\n",
    "\n",
    "# Ensure all entries in 'cleaned_text' are strings. Replace non-string entries with an empty string.\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Apply remove_punctuation function\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_english_alphabets)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
