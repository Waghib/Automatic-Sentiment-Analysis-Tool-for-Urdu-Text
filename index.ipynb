{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0   \n",
       "3                                       نہیں پائین 😎           0.0   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0   \n",
       "\n",
       "   Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
       "0         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN        NaN         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'urdu_sarcastic_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['آئی', 'آئے', 'آج', 'آخر', 'آخرکبر', 'آدهی', 'آًب', 'آٹھ', 'آیب', 'اة']\n"
     ]
    }
   ],
   "source": [
    "# Load the stopwords from the text file\n",
    "with open('stopwords-ur.txt', 'r', encoding='utf-8') as file:\n",
    "    urdu_stopwords = file.read().splitlines()\n",
    "\n",
    "# Check the first few stopwords\n",
    "print(urdu_stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>🤣😂😂 لینے میری شادی فسادن کوجی نہیں چاہیے 😐😐😐🤣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی اپوزیش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>`` مراد علی شاہ بھیس میں ڈی جی ایس '' حامد میر😁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "3                                       نہیں پائین 😎   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0      🤣😂😂 لینے میری شادی فسادن کوجی نہیں چاہیے 😐😐😐🤣  \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی اپوزیش...  \n",
       "3                                       نہیں پائین 😎  \n",
       "4    `` مراد علی شاہ بھیس میں ڈی جی ایس '' حامد میر😁  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove stopwords, handling non-string values\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        words = text.split()  # Split text into words\n",
    "        cleaned_text = ' '.join([word for word in words if word not in urdu_stopwords])\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return text  # Return the text unchanged if it's not a string\n",
    "\n",
    "# Apply the stopword removal to the 'urdu_text' column\n",
    "df['cleaned_text'] = df['urdu_text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the cleaned text\n",
    "df[['urdu_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Punctuation, Emojis, and Hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>نہیں پائین</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "3                                       نہیں پائین 😎   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...  \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...  \n",
       "3                                         نہیں پائین  \n",
       "4  مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # 1. Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # 2. Remove Hashtags\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        \n",
    "        # 3. Remove Punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # 4. Remove all emojis\n",
    "        text = re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FAFF]', '', text)\n",
    "\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return text  # Return unchanged if not a string\n",
    "\n",
    "# Apply the clean_text function to the 'urdu_text' column\n",
    "df['cleaned_text'] = df['urdu_text'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "df[['urdu_text', 'cleaned_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Short Conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "3                                       نہیں پائین 😎   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...  \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...  \n",
       "3                                                     \n",
       "4  مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to filter short conversations\n",
    "def filter_short_conversations(text):\n",
    "    if isinstance(text, str):\n",
    "        # Count the number of words\n",
    "        word_count = len(text.split())\n",
    "        # Return the text if it has 3 or more words, otherwise return an empty string\n",
    "        return text if word_count >= 3 else ''\n",
    "    return text  # Return unchanged if not a string\n",
    "\n",
    "# Apply the filter_short_conversations function to the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(filter_short_conversations)\n",
    "\n",
    "# Save the cleaned text to a separate CSV file\n",
    "df[['cleaned_text']].to_csv('cleaned_urdu_text.csv', index=False, encoding='utf-8')\n",
    "# Display the results\n",
    "df[['urdu_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Some additional preprocessing techniques (normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 22:12:52.449409: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-29 22:12:52.453762: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-29 22:12:52.547268: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-29 22:12:52.548838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 22:12:54.570750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/waghib/Desktop/NLP/Automatic-Sentiment-Analysis-Tool-for-Urdu-Text/nlp_assignment/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text\n",
       "0  ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...\n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...\n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
       "3                                                   \n",
       "4  مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given text str, replace one or more spacings with a single space, \n",
    "# and one or more linebreaks with a single newline. \n",
    "\n",
    "from urduhack.preprocessing import normalize_whitespace\n",
    "\n",
    "# Apply normalization to the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: normalize_whitespace(x) if pd.notnull(x) else x)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the normalized text\n",
    "df[['cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...\n",
      "1    چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...\n",
      "2    کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing some of the additional urdu punctuations from the text\n",
    "\n",
    "from urduhack.preprocessing import remove_punctuation\n",
    "\n",
    "# Ensure all entries in 'cleaned_text' are strings. Replace non-string entries with an empty string.\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Apply remove_punctuation function\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_punctuation)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...\n",
      "1    چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...\n",
      "2    کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove accents from any accented unicode characters in text str, either by transforming them \n",
    "# into ascii equivalents or removing them entirely.\n",
    "\n",
    "from urduhack.preprocessing import remove_accents\n",
    "\n",
    "# Ensure all entries in 'cleaned_text' are strings. Replace non-string entries with an empty string.\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Apply remove_punctuation function\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_accents)\n",
    "\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waghib/Desktop/NLP/Automatic-Sentiment-Analysis-Tool-for-Urdu-Text/nlp_assignment/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...\n",
      "1    چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...\n",
      "2    کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی تھے...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This function replaces English digits with Urdu digits.\n",
    "from LughaatNLP import LughaatNLP\n",
    "\n",
    "# Initialize the LughaatNLP object\n",
    "urdu_text_processing = LughaatNLP()\n",
    "\n",
    "# Apply the replace_digits function to each row in the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: urdu_text_processing.replace_digits(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the result 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہیں چ...\n",
      "1    چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...\n",
      "2    کامران خان اپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کے بھیس میں ڈی جی ائی ایس ائی تھے...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This function removes all non-Urdu characters, numbers, and special characters, just leaving only pure \n",
    "# Urdu text even not special character used in urdu.\n",
    "\n",
    "# Apply the just_urdu function to each row in the 'cleaned_text' column\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: urdu_text_processing.just_urdu(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the result 'cleaned_text'\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spell checker\n",
    "\n",
    "# # Initialize the LughaatNLP object\n",
    "# spell_checker = LughaatNLP()\n",
    "\n",
    "# # Apply the spell_check function to each row in the 'cleaned_text' column\n",
    "# df['cleaned_text'] = df['cleaned_text'].apply(lambda x: spell_checker.corrected_sentence_spelling(x, 60) if isinstance(x, str) else x)\n",
    "\n",
    "# # Save the updated data to a new CSV file\n",
    "# df[['cleaned_text']].to_csv('normalized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# # Display the result 'cleaned_text'\n",
    "# print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہو لینہ دہ میری شادی فسادن ٹھیک ہہ کوجی نہا چاہیہ\n",
      "1    چل مہمانا ما کھانا سرو کر چڑیل چاچی نا دسدی اں ما\n",
      "2    کامران خان اپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کہ بھیس ما ڈی جی ائی ایس ائی تھہ ...\n",
      "Name: stemmed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Import LughaatNLP for stemming and lemmatization\n",
    "\n",
    "# Function to apply stemming only\n",
    "def apply_stemming(text):\n",
    "    if isinstance(text, str):\n",
    "        # Apply stemming\n",
    "        stemmed_text = urdu_text_processing.urdu_stemmer(text)\n",
    "        return stemmed_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply stemming to the 'cleaned_text' column\n",
    "df['stemmed_text'] = df['cleaned_text'].apply(apply_stemming)\n",
    "\n",
    "# Save the stemmed output to a new CSV file\n",
    "df[['stemmed_text']].to_csv('stemmed_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'stemmed_text'\n",
    "print(df['stemmed_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ہونا لینا دینا میرا شادی فسادن ٹھیک ہونا کوجی ...\n",
      "1    چلنا مہمان میں کھا سرا کرنا چڑیل چاچی نوں دسدی...\n",
      "2    کامران خان اپکی دن بھریہ زمہ داری لگنا جانا اپ...\n",
      "3                                                     \n",
      "4    مراد علی شاہ کم بھیس میں ڈی جینا ائی ایس ائی ت...\n",
      "Name: lemmatized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to apply lemmatization only\n",
    "def apply_lemmatization(text):\n",
    "    if isinstance(text, str):\n",
    "        # Apply lemmatization\n",
    "        lemmatized_text = urdu_text_processing.lemmatize_sentence(text)\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply lemmatization to the 'cleaned_text' column\n",
    "df['lemmatized_text'] = df['cleaned_text'].apply(apply_lemmatization)\n",
    "\n",
    "# Save the lemmatized output to a new CSV file\n",
    "df[['lemmatized_text']].to_csv('lemmatized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 20 rows of 'lemmatized_text'\n",
    "print(df['lemmatized_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [ہونا, لینا, دینا, میرا, شادی, فسادن, ٹھیک, ہو...\n",
      "1    [چلنا, مہمان, میں, کھا, سرا, کرنا, چڑیل, چاچی,...\n",
      "2    [کامران, خان, اپکی, دن, بھریہ, زمہ, داری, لگنا...\n",
      "3                                                   []\n",
      "4    [مراد, علی, شاہ, کم, بھیس, میں, ڈی, جینا, ائی,...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This function tokenizes the Urdu text into individual tokens\n",
    "\n",
    "# Apply the urdu_tokenize function to each row in the 'lemmatized_text' column\n",
    "df['tokenized_text'] = df['lemmatized_text'].apply(\n",
    "    lambda x: urdu_text_processing.urdu_tokenize(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Save the tokenized data to a new CSV file\n",
    "df[['tokenized_text']].to_csv('tokenized_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display the first 5 rows of the tokenized text\n",
    "print(df['tokenized_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tf-IDF (Term Frequency-Inverse Document Frequency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words with highest TF-IDF scores:\n",
      "ہونا    1379.796968\n",
      "میں     1146.799896\n",
      "کم       962.396668\n",
      "کرنا     619.291894\n",
      "کو       526.431342\n",
      "سے       516.883089\n",
      "نہیں     498.592380\n",
      "کا       477.211109\n",
      "بھی      446.767171\n",
      "اور      441.691920\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Join the tokenized text into a single string for each document\n",
    "df['joined_text'] = df['tokenized_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the joined text to compute TF-IDF scores\n",
    "tfidf_matrix = vectorizer.fit_transform(df['joined_text'])\n",
    "\n",
    "# Get the words corresponding to the features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Sum the TF-IDF scores for each word across all documents\n",
    "tfidf_sum = tfidf_df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Get the top 10 words with the highest TF-IDF scores\n",
    "top_tfidf_words = tfidf_sum.head(10)\n",
    "\n",
    "# Display the top 10 words and their TF-IDF scores\n",
    "print(\"Top 10 words with highest TF-IDF scores:\")\n",
    "print(top_tfidf_words)\n",
    "\n",
    "# Save the top TF-IDF words to a CSV file\n",
    "top_tfidf_words.to_csv('top_tfidf_words.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words most similar to 'اچھا': [('مشکل', 0.9648818969726562), ('افسوس', 0.9622622132301331), ('اچھی', 0.960913896560669), ('ہمیں', 0.959526002407074), ('مجھے', 0.9595121145248413)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the fixed tokenized dataset\n",
    "tokenized_sentences = df['tokenized_text'].tolist()\n",
    "\n",
    "# Train a Word2Vec model\n",
    "# Parameters: \n",
    "#   size=100: Vector size (embedding dimension)\n",
    "#   window=5: Context window size\n",
    "#   min_count=1: Ignores words with frequency lower than this\n",
    "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the trained Word2Vec model for future use\n",
    "word2vec_model.save(\"urdu_word2vec_fixed.model\")\n",
    "\n",
    "# finding similar words for \"اچھا\"\n",
    "try:\n",
    "    similar_words = word2vec_model.wv.most_similar(\"اچھا\", topn=5)\n",
    "    print(\"Top 5 words most similar to 'اچھا':\", similar_words)\n",
    "\n",
    "    # Save the similar words to a CSV file\n",
    "    similar_words_df = pd.DataFrame(similar_words, columns=['Word', 'Similarity'])\n",
    "    similar_words_df.to_csv('similar_words_acha.csv', index=False, encoding='utf-8')\n",
    "\n",
    "except KeyError:\n",
    "    print(\"Word 'اچھا' not found in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
